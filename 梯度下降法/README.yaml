梯度下降法 :
  - 不是机器学习算法
  - 是基于搜索的最优化方法
  - 超参数:
      - 学习率
      - 初始点
  - 作用 :
      - 最小化一个损失函数
      - 导数可以代表方向, 对应J(损失函数)增大的方向
      - 梯度下降法找到的是局部最优解，不一定是全局最优解 :
          -  解决方案:
               - 随机初始化起始点
  - 梯度下降法的向量化 :
      - 将梯度下降的公式进行向量化拆分，提高运行速度
  - 梯度下降法对比正规方程法的优点 :
      - 在数据量比较大时, 梯度下降法的运算速度远超正规方程法的速度
  - 随机梯度下降法（SGD) :
      - 每次进行梯度下降时, 只随机取一个样本进行计算, 并且学习率随着迭代次数增大而减小

  - 批量梯度下降法(BGD):

  - 小批量梯度下降法(MBGD):
